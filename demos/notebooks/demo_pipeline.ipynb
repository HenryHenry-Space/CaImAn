{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Be sure to clear all outputs before pushing\n",
    "# !git branch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNMF demo pipeline\n",
    "This demo presents a full pipeline for the analysis of a two-photon calcium imaging dataset using the CaImAn (**Ca**lcium **Im**aging **An**alysis) software package. It demonstrates how to use Caiman's built-in tools for motion correction, source separation (extraction of the location and calcium trace from each discovered component), and deconvolution (estimation of the spikes that generated the calcium signal). Graphically, we can represent the pipeline as follows:\n",
    "\n",
    "![temporary workflow image](../../docs/img/quickintro.png)\n",
    "\n",
    "Below, we walk through how to use Caiman to implement these steps using a dataset provided courtesy of Sue Ann Koay and David Tank (Princeton University). \n",
    "\n",
    "This demo uses the constrained nonnegative matrix factorization (CNMF) algorithm, which is best for data sets with low background noise such as two-photon data (or some 1p data such as some light sheet). For a demo pipeline of a 1p microendoscopic data set see `demo_pipeline_cnmfE.ipynb`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting help\n",
    "More detailed background information can be found in the [original CNMF paper](https://pubmed.ncbi.nlm.nih.gov/26774160/) and [the Caiman paper](https://pubmed.ncbi.nlm.nih.gov/30652683/). If you have questions about this demo, or the underlying algorithms, you can ask questions at our [gitter channel](https://app.gitter.im/#/room/#agiovann_Constrained_NMF:gitter.im). If you find a bug, or there are features you would like to see added, feel free to [open an issue](https://github.com/flatironinstitute/CaImAn/issues)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import psutil\n",
    "from pathlib import Path\n",
    "import glob\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import bokeh.plotting as bpl\n",
    "try:\n",
    "    cv2.setNumThreads(0)\n",
    "except():\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    if __IPYTHON__:\n",
    "        # reloads modules automatically when they are changed\n",
    "        ipython().magic('load_ext autoreload')\n",
    "        ipython().magic('autoreload 2')\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "import caiman as cm\n",
    "from caiman.motion_correction import MotionCorrect\n",
    "from caiman.source_extraction.cnmf import cnmf as cnmf\n",
    "from caiman.source_extraction.cnmf import params as params\n",
    "from caiman.utils.utils import download_demo\n",
    "from caiman.utils.visualization import plot_contours, nb_view_patches, nb_plot_contour\n",
    "\n",
    "bpl.output_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up logger (optional)\n",
    "Before getting started, we can optionally set up a logger. Skip this section if you don't want a logger.\n",
    "\n",
    "Python has a powerful built-in [logging module](https://docs.python.org/3/library/logging.html) for generating log messages while a program is running: it lets you print customized statements and set a logging level to determine how verbose the outputs will be. This way, you will only receive messages above the severity threshold you set: `logging.DEBUG`, `logging.INFO`, `logging.WARNING`, `logging.ERROR`, or `logging.CRITICAL`. For instance, seetting the threshold to `logging.DEBUG` will print out every logging statement, while setting it to `logging.ERROR` will print out only errors and critical problems. This system gives much more flexibility and control than interspersing `print()` statements throughought your code when debugging. \n",
    "\n",
    "Our custom formatted log string is defined in the `log_format` parameter below, which draws from a predefined [set of attributes](https://docs.python.org/3/library/logging.html#logrecord-attributes) provided by the logging module. We have set each log to display the time, severity level, filename/function name/line number of the file creating the log, process ID, and the actual log message. \n",
    "\n",
    "While logging is especially helpful when running code on a server, it can also be helpful to get feedback in real time on your personal machine, either to audit progress or diagnose problems when debugging. If you set this feature up by running the following cell, the logs will by default go to console. If you want to direct your log to file (which you can indicate with `use_logfile = True`), then it will automatically be directed to your `caiman_data/temp` directory as defined in the `caiman.paths` module. You can set another path with the `filename` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_logfile = False # If set to True, will log to file\n",
    "if use_logfile:\n",
    "    log_file = Path(cm.paths.get_tempdir()) / 'cnmf_demo.log' # \n",
    "    print(f\"Will save logging data to {tmp_file}\")\n",
    "else:\n",
    "    log_file = None\n",
    "log_format = \"{asctime} - {levelname} - [{filename} {funcName}() {lineno}] - pid {process} - {message}\"\n",
    "logging.basicConfig(format=log_format,\n",
    "                    filename=log_file, \n",
    "                    level=logging.INFO, style=\"{\") #DEBUG, INFO, WARNING, ERROR, CRITICAL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select files for processing\n",
    "Many acquisition systems break up data from a single session across multiple files. This demo shows how to work with lists of filepaths that represent multiple movies from the same recording session. While this demo works with `tif` files, Caiman can handle movies in multiple common formats such as:\n",
    "\n",
    "    tiff, hdf5, nwb, avi, zarr, h5, npz, n5\n",
    "    \n",
    "In the following cell, Caimain's `download_demo()` function will first check to see if the demo movies exist in the specified directory. If they do not, the files will be downloaded. The function returns the full file path which we append to the `filenames` list.\n",
    "\n",
    "If you adapt this demo for your data make sure to include the complete path(s) when you place them in the `filenames` variable. There are also functions that take in single filenames instead of lists, as discussed in [Caiman's documentation](https://caiman.readthedocs.io/en/master/Handling_Movies.html#). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = []\n",
    "save_folder = 'cnmf_demo_data'  # folder inside .caiman_data/example_movies where files will be saved\n",
    "try:\n",
    "    filenames.append(download_demo('Sue_Split1.tif',save_folder))\n",
    "    filenames.append(download_demo('Sue_Split2.tif',save_folder))\n",
    "except KeyError:\n",
    "    # this is temporary until Sue_Split makes it into main repo list\n",
    "    dirname = cm.paths.caiman_datadir()\n",
    "    save_path = dirname + save_folder\n",
    "    filenames = [save_path + 'Sue_Split1.tif', save_path + 'Sue_Split2.tif']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note if you have recorded data across many days or weeks (for instance), and you need to register neurons across multiple recording sessions, this is a different use case. We do have a demo for that: see `demo_multisession_registration.ipynb`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and play the movie (optional)   \n",
    "Once you have set up the desired list of movie(s) for analysis, you can load the data, concatenated into a single movie object, for viewing.  This will require loading all of the data into memory -- in general this is not needed by Caiman's pipeline, which uses out-of-core processing to avoid overwhelming RAM. But for the relatively small data files used in this demo, it should be fine on most computers. Collectively, they take up about 350MB of RAM: if you aren't sure how much memory you have available, you can use the `psutil.virtual_memory()` function.\n",
    "\n",
    "Once the movie object is generated (with `load_movie_chain()`), it can then be played using `movie.play()` which has multiple parameters you can play with, including: \n",
    "\n",
    "    gain (brightness) \n",
    "    fr (frame rate)    \n",
    "    magnification (int)  \n",
    "    qmax, q_min (percentile for vmax, vmin plotting values)    \n",
    "    plot_text (Bool) to show the frame number    \n",
    "    \n",
    "As always, to see the full documentation in Jupyter, you can enter `movie.play?` in a cell.\n",
    "\n",
    "Displaying the movie uses the OpenCV library, so if you set `display_movie` to True, the following cell will run a blocking function (a function that blocks execution of all other code until it is stopped), opening a separate PyQt window which doesn't run in Jupyter. You will need to press `q` on that window to close it. \n",
    "\n",
    "We resample the movie in time according by `downsample_ratio` using `resize()` before playing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_movie = True\n",
    "if display_movie:\n",
    "    movie_orig = cm.load_movie_chain(fnames_full_path)\n",
    "    downsampling_ratio = 0.2\n",
    "    movie_orig.resize(fz=downsampling_ratio).play(gain=1.3,\n",
    "                                                  q_max=99.5, \n",
    "                                                  fr=30, \n",
    "                                                  plot_text=True,\n",
    "                                                  magnification=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up some parameters\n",
    "We set some parameters that are relevant to the file, and then parameters for motion correction, processing with CNMF and component quality evaluation. Note that the dataset `Sue_2x_3000_40_-46.tif` has been spatially downsampled by a factor of 2 and has a lower than usual spatial resolution (2um/pixel). As a result several parameters (`gSig, strides, max_shifts, rf, stride_cnmf`) have lower values (halved compared to a dataset with spatial resolution 1um/pixel)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset dependent parameters\n",
    "fr = 30                             # imaging rate in frames per second\n",
    "decay_time = 0.4                    # length of a typical transient in seconds\n",
    "\n",
    "# motion correction parameters\n",
    "strides = (48, 48)          # start a new patch for pw-rigid motion correction every x pixels\n",
    "overlaps = (24, 24)         # overlap between pathes (size of patch strides+overlaps)\n",
    "max_shifts = (6,6)          # maximum allowed rigid shifts (in pixels)\n",
    "max_deviation_rigid = 3     # maximum shifts deviation allowed for patch with respect to rigid shifts\n",
    "pw_rigid = True             # flag for performing non-rigid motion correction\n",
    "\n",
    "# parameters for source extraction and deconvolution\n",
    "p = 1                       # order of the autoregressive system\n",
    "gnb = 2                     # number of global background components\n",
    "merge_thr = 0.85            # merging threshold, max correlation allowed\n",
    "rf = 15                     # half-size of the patches in pixels. e.g., if rf=25, patches are 50x50\n",
    "stride_cnmf = 6             # amount of overlap between the patches in pixels\n",
    "K = 4                       # number of components per patch\n",
    "gSig = [4, 4]               # expected half size of neurons in pixels\n",
    "method_init = 'greedy_roi'  # initialization method (if analyzing dendritic data using 'sparse_nmf')\n",
    "ssub = 1                    # spatial subsampling during initialization\n",
    "tsub = 1                    # temporal subsampling during intialization\n",
    "\n",
    "# parameters for component evaluation\n",
    "min_SNR = 2.0               # signal to noise ratio for accepting a component\n",
    "rval_thr = 0.85              # space correlation threshold for accepting a component\n",
    "cnn_thr = 0.99              # threshold for CNN based classifier\n",
    "cnn_lowest = 0.1 # neurons with cnn probability lower than this value are rejected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a parameters object\n",
    "You can creating a parameters object by passing all the parameters as a single dictionary. Parameters not defined in the dictionary will assume their default values. The resulting `params` object is a collection of subdictionaries pertaining to the dataset to be analyzed `(params.data)`, motion correction `(params.motion)`, data pre-processing `(params.preprocess)`, initialization `(params.init)`, patch processing `(params.patch)`, spatial and temporal component `(params.spatial), (params.temporal)`, quality evaluation `(params.quality)` and online processing `(params.online)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opts_dict = {'fnames': filenames,\n",
    "            'fr': fr,\n",
    "            'decay_time': decay_time,\n",
    "            'strides': strides,\n",
    "            'overlaps': overlaps,\n",
    "            'max_shifts': max_shifts,\n",
    "            'max_deviation_rigid': max_deviation_rigid,\n",
    "            'pw_rigid': pw_rigid,\n",
    "            'p': p,\n",
    "            'nb': gnb,\n",
    "            'rf': rf,\n",
    "            'K': K, \n",
    "            'gSig': gSig,\n",
    "            'stride': stride_cnmf,\n",
    "            'method_init': method_init,\n",
    "            'rolling_sum': True,\n",
    "            'only_init': True,\n",
    "            'ssub': ssub,\n",
    "            'tsub': tsub,\n",
    "            'merge_thr': merge_thr, \n",
    "            'min_SNR': min_SNR,\n",
    "            'rval_thr': rval_thr,\n",
    "            'use_cnn': True,\n",
    "            'min_cnn_thr': cnn_thr,\n",
    "            'cnn_lowest': cnn_lowest}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opts = params.CNMFParams(params_dict=opts_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up cluster\n",
    "To enable parallel processing a (local) cluster needs to be set up. This is done with the `setup_cluster()` function  below, which sets up a pool of processors using the multiprocessing package. \n",
    "\n",
    "The `backend` parameter determines the type of cluster used. The default value `'local'` uses the multiprocessing package. The `ipyparallel` option is also available. More information on these choices can be found [here](https://github.com/flatironinstitute/CaImAn/blob/master/docs/CLUSTER.md). You can set the number of processes (cpu cores) to use with the `n_processes` variable: the default value `None` will lead to the function selecting one less than the total number available. \n",
    "\n",
    "The output variable `dview` returned by the function is the multicore object that will be used in subsequent processing steps (for multiprocessing, it is a multiprocessing pool). `dview` will be fed into subsequent stages in the processing pipeline (the name stands for `DirectView` which is from the ipyparallel package). In these later steps, if you set `dview=dview`, then parallel processing will be used. If instead you use `dview=None` then no parallel processing will be used. This latter option can sometimes be useful when debugging, as the error messages are often be simpler when using a single processor. \n",
    "\n",
    "One note for performance: if you hit memory issues, you may want to lower the number of processors you are using. You can see how many processors you have available with `psutil.cpu_count()`. Each processor uses more RAM, and on a workstation with many processors, you can often get much better performance by reducing `n_processes`, and the best way to determine the optimal number is often by trial and error. The reason we do not automatically set it to the total number of cores is because it typically leads to worse performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"You have {psutil.cpu_count()} CPUs available in your current environment\")\n",
    "processors_to_use = None  # Set to smaller number if you have memory problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start a cluster for parallel processing \n",
    "# note if a cluster already exists it will be closed so a new session will be opened\n",
    "if 'dview' in locals():  # locals contains list of current local variables\n",
    "    print('Closing previous cluster')\n",
    "    cm.stop_server(dview=dview)\n",
    "print(\"Setting up new cluster\")\n",
    "c, dview, n_processes = cm.cluster.setup_cluster(backend='local', \n",
    "                                                 n_processes=processors_to_use, \n",
    "                                                 single_thread=False,\n",
    "                                                 ignore_preexisting=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motion Correction\n",
    "First we create a motion correction object with the parameters specified. Note that the file is not loaded in memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first we create a motion correction object with the parameters specified\n",
    "mc = MotionCorrect(fnames, dview=dview, **opts.get_group('motion'))\n",
    "# note that the file is not loaded in memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now perform motion correction. From the movie above we see that the dateset exhibits non-uniform motion. We will perform piecewise rigid motion correction using the NoRMCorre algorithm. This has already been selected by setting `pw_rigid=True` when defining the parameters object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture\n",
    "#%% Run piecewise-rigid motion correction using NoRMCorre\n",
    "mc.motion_correct(save_movie=True)\n",
    "m_els = cm.load(mc.fname_tot_els)\n",
    "border_to_0 = 0 if mc.border_nan == 'copy' else mc.border_to_0 \n",
    "    # maximum shift to be used for trimming against NaNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect the results by comparing the original movie. A more detailed presentation of the motion correction method can be found in the [demo motion correction](./demo_motion_correction.ipynb) notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% compare with original movie\n",
    "display_movie = False\n",
    "if display_movie:\n",
    "    movie_orig = cm.load_movie_chain(fnames)\n",
    "    ds_ratio = 0.2\n",
    "    cm.concatenate([movie_orig.resize(1, 1, ds_ratio) - mc.min_mov*mc.nonneg_movie,\n",
    "                    m_els.resize(1, 1, ds_ratio)], \n",
    "                   axis=2).play(fr=60, gain=15, magnification=2, offset=0)  # press q to exit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory mapping \n",
    "\n",
    "The cell below memory maps the file in order `'C'` and then loads the new memory mapped file. The saved files from motion correction are memory mapped files stored in `'F'` order. Their paths are stored in `mc.mmap_file`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% MEMORY MAPPING\n",
    "# memory map the file in order 'C'\n",
    "fname_new = cm.save_memmap(mc.mmap_file, base_name='memmap_', order='C',\n",
    "                           border_to_0=border_to_0, dview=dview) # exclude borders\n",
    "\n",
    "# now load the file\n",
    "Yr, dims, T = cm.load_memmap(fname_new)\n",
    "images = np.reshape(Yr.T, [T] + list(dims), order='F') \n",
    "    #load frames in python format (T x X x Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now restart the cluster to clean up memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% restart cluster to clean up memory\n",
    "cm.stop_server(dview=dview)\n",
    "c, dview, n_processes = cm.cluster.setup_cluster(\n",
    "    backend='multiprocessing', n_processes=None, single_thread=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run CNMF on patches in parallel\n",
    "\n",
    "- The FOV is split is different overlapping patches that are subsequently processed in parallel by the CNMF algorithm.\n",
    "- The results from all the patches are merged with special attention to idendtified components on the border.\n",
    "- The results are then refined by additional CNMF iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "#%% RUN CNMF ON PATCHES\n",
    "# First extract spatial and temporal components on patches and combine them\n",
    "# for this step deconvolution is turned off (p=0). If you want to have\n",
    "# deconvolution within each patch change params.patch['p_patch'] to a\n",
    "# nonzero value\n",
    "cnm = cnmf.CNMF(n_processes, params=opts, dview=dview)\n",
    "cnm = cnm.fit(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the entire pipeline up to this point with one command\n",
    "It is possible to run the combined steps of motion correction, memory mapping, and cnmf fitting in one step as shown below. The command is commented out since the analysis has already been performed. It is recommended that you familiriaze yourself with the various steps and the results of the various steps before using it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnm1 = cnmf.CNMF(n_processes, params=opts, dview=dview)\n",
    "# cnm1.fit_file(motion_correct=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspecting the results\n",
    "Briefly inspect the results by plotting contours of identified components against correlation image.\n",
    "The results of the algorithm are stored in the object `cnm.estimates`. More information can be found in the definition of the `estimates` object and in the [wiki](https://github.com/flatironinstitute/CaImAn/wiki/Interpreting-Results)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% plot contours of found components\n",
    "Cn = cm.local_correlations(images.transpose(1,2,0))\n",
    "Cn[np.isnan(Cn)] = 0\n",
    "cnm.estimates.plot_contours_nb(img=Cn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-run (seeded) CNMF  on the full Field of View  \n",
    "You can re-run the CNMF algorithm seeded on just the selected components from the previous step. Be careful, because components rejected on the previous step will not be recovered here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "#%% RE-RUN seeded CNMF on accepted patches to refine and perform deconvolution \n",
    "cnm2 = cnm.refit(images, dview=dview)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Component Evaluation\n",
    "\n",
    "The processing in patches creates several spurious components. These are filtered out by evaluating each component using three different criteria:\n",
    "\n",
    "- the shape of each component must be correlated with the data at the corresponding location within the FOV\n",
    "- a minimum peak SNR is required over the length of a transient\n",
    "- each shape passes a CNN based classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% COMPONENT EVALUATION\n",
    "# the components are evaluated in three ways:\n",
    "#   a) the shape of each component must be correlated with the data\n",
    "#   b) a minimum peak SNR is required over the length of a transient\n",
    "#   c) each shape passes a CNN based classifier\n",
    "\n",
    "cnm2.estimates.evaluate_components(images, cnm2.params, dview=dview)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot contours of selected and rejected components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% PLOT COMPONENTS\n",
    "cnm2.estimates.plot_contours_nb(img=Cn, idx=cnm2.estimates.idx_components)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View traces of accepted and rejected components. Note that if you get data rate error you can start Jupyter notebooks using:\n",
    "'jupyter notebook --NotebookApp.iopub_data_rate_limit=1.0e10'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accepted components\n",
    "cnm2.estimates.nb_view_components(img=Cn, idx=cnm2.estimates.idx_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rejected components\n",
    "if len(cnm2.estimates.idx_components_bad) > 0:\n",
    "    cnm2.estimates.nb_view_components(img=Cn, idx=cnm2.estimates.idx_components_bad)\n",
    "else:\n",
    "    print(\"No components were rejected.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract DF/F values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Extract DF/F values\n",
    "cnm2.estimates.detrend_df_f(quantileMin=8, frames_window=250)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select only high quality components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnm2.estimates.select_components(use_object=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display final results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnm2.estimates.nb_view_components(img=Cn, denoised_color='red')\n",
    "print('you may need to change the data rate to generate this one: use jupyter notebook --NotebookApp.iopub_data_rate_limit=1.0e10 before opening jupyter notebook')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Closing, saving, and creating denoised version\n",
    "### You can save an hdf5 file with all the fields of the cnmf object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results = False\n",
    "if save_results:\n",
    "    cnm2.save('analysis_results.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop cluster and clean up log files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% STOP CLUSTER and clean up log files\n",
    "cm.stop_server(dview=dview)\n",
    "log_files = glob.glob('*_LOG_*')\n",
    "for log_file in log_files:\n",
    "    os.remove(log_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View movie with the results\n",
    "We can inspect the denoised results by reconstructing the movie and playing alongside the original data and the resulting (amplified) residual movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnm2.estimates.play_movie(images, q_max=99.9, gain_res=2,\n",
    "                                  magnification=2,\n",
    "                                  bpx=border_to_0,\n",
    "                                  include_bck=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The denoised movie can also be explicitly constructed using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% reconstruct denoised movie\n",
    "denoised = cm.movie(cnm2.estimates.A.dot(cnm2.estimates.C) + \\\n",
    "                    cnm2.estimates.b.dot(cnm2.estimates.f)).reshape(dims + (-1,), order='F').transpose([2, 0, 1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
